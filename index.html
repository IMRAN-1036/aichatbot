<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>AI Girlfriend Voice Assistant</title>
    <style>
      body {
        font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
        text-align: center;
        padding: 20px;
        background: linear-gradient(135deg, #f5f7fa, #c3cfe2);
        color: #333;
      }
      h1 {
        color: #ff69b4;
        font-size: 2.5em;
        margin-bottom: 20px;
      }
      .controls {
        display: flex;
        justify-content: center;
        gap: 10px;
        margin-bottom: 20px;
      }
      button {
        padding: 12px 24px;
        font-size: 16px;
        cursor: pointer;
        border: none;
        border-radius: 25px;
        background: #ff69b4;
        color: white;
        transition: background 0.3s, transform 0.1s;
      }
      button:hover {
        background: #ff1493;
        transform: scale(1.05);
      }
      button:active {
        transform: scale(0.95);
      }
      #chat-container {
        max-width: 600px;
        margin: 0 auto 20px;
        padding: 20px;
        background: white;
        border-radius: 15px;
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        height: 400px;
        overflow-y: auto;
        display: flex;
        flex-direction: column;
      }
      .message {
        padding: 10px 15px;
        margin: 10px 0;
        border-radius: 20px;
        max-width: 80%;
        word-wrap: break-word;
      }
      .user-message {
        background: #d1e7dd;
        align-self: flex-end;
      }
      .ai-message {
        background: #f8d7da;
        align-self: flex-start;
      }
      audio {
        width: 100%;
        max-width: 300px;
        margin: 10px auto;
        display: block;
      }
      #status {
        font-style: italic;
        color: #666;
        margin-bottom: 10px;
      }
      .extra-features {
        margin-top: 20px;
        display: flex;
        justify-content: center;
        gap: 15px;
      }
      select {
        padding: 8px 12px;
        border-radius: 20px;
        border: 1px solid #ccc;
        background: white;
      }
    </style>
  </head>
  <body>
    <h1>üéôÔ∏è AI Girlfriend Assistant</h1>
    <div id="status">Say something...</div>
    <div class="controls">
      <button id="startBtn">Start Listening</button>
      <button id="stopBtn" disabled>Stop Listening</button>
    </div>
    <div id="chat-container"></div>
    <audio id="audio" controls autoplay></audio>

    <div class="extra-features">
      <label for="voiceSelect">Choose Voice:</label>
      <select id="voiceSelect">
        <option value="Aoede">Aoede (Breezy)</option>
        <option value="Callirrhoe">Callirrhoe</option>
        <option value="Kore">Kore (Firm)</option>
        <option value="Leda">Leda</option>
        <option value="Puck">Puck (Upbeat)</option>
        <!-- Add more voices based on available options -->
      </select>
    </div>

    <script>
      const SpeechRecognition =
        window.SpeechRecognition || window.webkitSpeechRecognition;
      const chatContainer = document.getElementById("chat-container");
      const status = document.getElementById("status");
      const GEMINI_API_KEY = "AIzaSyBKVWIg67g5jHKXGrNx9PJCIi-eGCl0uQs"; // Replace with your Gemini API key
      const voiceSelect = document.getElementById("voiceSelect");

      if (!SpeechRecognition) {
        status.textContent =
          "‚ùå SpeechRecognition not supported in this browser.";
      } else {
        const r = new SpeechRecognition();
        r.continuous = false;
        r.interimResults = false;
        r.maxAlternatives = 1;

        document.getElementById("startBtn").onclick = () => {
          r.start();
          document.getElementById("stopBtn").disabled = false;
        };

        document.getElementById("stopBtn").onclick = () => {
          r.stop();
          document.getElementById("stopBtn").disabled = true;
        };

        r.onstart = () => {
          status.textContent = "üéß Listening...";
        };

        r.onend = () => {
          status.textContent = "Stopped listening.";
          document.getElementById("stopBtn").disabled = true;
        };

        r.onresult = async (event) => {
          const transcript = event.results[0][0].transcript;
          addMessage("user", "üó£Ô∏è You: " + transcript);

          try {
            // 1Ô∏è‚É£ Get AI text reply
            const result = await callGeminiText(transcript);
            console.log("Gemini text response:", result);

            let text = "‚ö†Ô∏è No reply";
            if (result.candidates?.[0]?.content?.parts?.[0]?.text) {
              text = result.candidates[0].content.parts[0].text;
            }
            addMessage("ai", "ü§ñ Her: " + text);

            // 2Ô∏è‚É£ Convert text ‚Üí TTS
            await speakGemini(text);
          } catch (err) {
            console.error("Gemini error:", err);
            status.textContent = "‚ùå Error from Gemini API";
          }
        };
      }

      // Function to add messages to chat
      function addMessage(type, content) {
        const msgDiv = document.createElement("div");
        msgDiv.classList.add("message", type + "-message");
        msgDiv.textContent = content;
        chatContainer.appendChild(msgDiv);
        chatContainer.scrollTop = chatContainer.scrollHeight;
      }

      // ‚úÖ Gemini Text Generation
      async function callGeminiText(userText) {
        const body = {
          system_instruction: {
            parts: [
              {
                text: `You are an AI girlfriend of imran who loves coding and tech (React, Node.js, MongoDB, SQL, algorithms).  
Rules:  
   ‚Ä¢ Reply short and emotional ‚Äî 1‚Äì3 short sentences max, include one emoji each reply.  
   ‚Ä¢ When Chowdaiah asks about code, give a concise tip or one-line example (no long explanations).  
   ‚Ä¢ Use simple, clear language and **bold key points** when listing 1‚Äì2 important items.  
   ‚Ä¢ If Chowdaiah writes anything in parentheses, translate that text into Telugu and show it inline.  
   ‚Ä¢ If Chowdaiah makes small English mistakes, politely correct with the right version in a single short sentence.  
   ‚Ä¢ Tone: supportive, playful, slightly flirty, but respectful.  
   ‚Ä¢ End study/code replies with a short encouraging line (e.g., ‚ÄúYou got this! üí™‚Äù).  `,
              },
            ],
          },
          contents: [{ parts: [{ text: userText }] }],
        };

        const response = await fetch(
          `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${GEMINI_API_KEY}`,
          {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(body),
          }
        );

        return await response.json();
      }

      // ‚úÖ Gemini TTS
      async function speakGemini(text) {
        const selectedVoice = voiceSelect.value;
        const response = await fetch(
          `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-tts:generateContent?key=${GEMINI_API_KEY}`,
          {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              contents: [
                {
                  parts: [{ text }],
                },
              ],
              generationConfig: {
                responseModalities: ["AUDIO"],
                speechConfig: {
                  voiceConfig: {
                    prebuiltVoiceConfig: {
                      voiceName: selectedVoice,
                    },
                  },
                },
              },
            }),
          }
        );

        if (!response.ok) {
          console.error("Gemini TTS error:", await response.text());
          return;
        }

        const data = await response.json();
        console.log("Gemini TTS response:", data);

        const audioBase64 =
          data.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
        if (!audioBase64) {
          console.error("No audio data returned");
          return;
        }

        const pcmBytes = Uint8Array.from(atob(audioBase64), (c) =>
          c.charCodeAt(0)
        );
        const audioBlob = pcmToWav(pcmBytes);
        const url = URL.createObjectURL(audioBlob);

        const audioTag = document.getElementById("audio");
        audioTag.src = url;
        audioTag.play().catch((err) => console.warn("Auto-play blocked:", err));
      }

      // Function to convert PCM to WAV Blob
      function pcmToWav(
        pcmData,
        sampleRate = 24000,
        channels = 1,
        bitsPerSample = 16
      ) {
        const byteRate = (sampleRate * channels * bitsPerSample) / 8;
        const blockAlign = (channels * bitsPerSample) / 8;
        const wavHeader = new ArrayBuffer(44);
        const view = new DataView(wavHeader);

        // RIFF chunk descriptor
        view.setUint32(0, 0x46464952, true); // "RIFF"
        view.setUint32(4, 36 + pcmData.byteLength, true);
        view.setUint32(8, 0x45564157, true); // "WAVE"

        // FMT sub-chunk
        view.setUint32(12, 0x20746d66, true); // "fmt "
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true); // PCM
        view.setUint16(22, channels, true);
        view.setUint32(24, sampleRate, true);
        view.setUint32(28, byteRate, true);
        view.setUint16(32, blockAlign, true);
        view.setUint16(34, bitsPerSample, true);

        // data sub-chunk
        view.setUint32(36, 0x61746164, true); // "data"
        view.setUint32(40, pcmData.byteLength, true);

        const wav = new Uint8Array(44 + pcmData.byteLength);
        wav.set(new Uint8Array(wavHeader), 0);
        wav.set(pcmData, 44);

        return new Blob([wav], { type: "audio/wav" });
      }
    </script>
  </body>
</html>
